{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2LmgcnR+WGhq9grOTeZi1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adnanagbaria/MLcourse/blob/main/Lec6_classification1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification: part 1\n",
        "Agenda:\n",
        "* Classification Tasks in ML\n",
        "* Logistic Regression\n",
        "* K-Nearest Neighbors (K-NN)\n",
        "* Support Vector Machines (SVM)\n",
        "* Kernel SVM\n",
        "* Bayes Theorem\n",
        "* Naive Bayes"
      ],
      "metadata": {
        "id": "C5VqZHlb4iLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Tasks in Machine Learning\n",
        "Classification is a type of supervised learning where the goal is to assign input data to discrete categories or labels.\n",
        "\n",
        "To build models that predict class membership for new, unseen data based on patterns learned from labeled training data.\n",
        "\n",
        "**Common Examples:**\n",
        "* Email Spam Detection → Spam / Not Spam\n",
        "* Medical Diagnosis → Disease / No Disease\n",
        "* Credit Approval → Approved / Rejected\n",
        "* Image Recognition → Dog / Cat / Car / Tree\n",
        "* Customer Churn Prediction → Will Leave / Will Stay\n",
        "\n",
        "**Key Characteristics:**\n",
        "* Output is categorical (unlike regression where output is numeric)\n",
        "* Can be:\n",
        "  * Binary: Two classes (e.g., 0 or 1)\n",
        "  * Multiclass: More than two classes (e.g., types of fruit)\n",
        "  * Multilabel: Assign multiple classes at once (e.g., tags in image)\n",
        "\n",
        "**Algorithms Often Used for Classification:**\n",
        "* Logistic Regression\n",
        "* K-Nearest Neighbors (K-NN)\n",
        "* Support Vector Machines (SVM)\n",
        "* Decision Trees / Random Forest\n",
        "* Naive Bayes\n",
        "* Neural Networks\n",
        "\n"
      ],
      "metadata": {
        "id": "ShvSIig25T3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression\n",
        "Logistic Regression is a classification algorithm used to predict the probability that an input belongs to a certain class — especially for binary classification problems (e.g., 0 or 1, yes or no, pass or fail).\n",
        "\n",
        "Instead of predicting a numeric value (as in linear regression), logistic regression predicts a probability using the sigmoid function.\n",
        "\n",
        "$\\hat{y} = \\frac{1}{1-e^{-z}}$, where $z = b_0 + b_1x1 + ... +b_nx_n$\n",
        "\n",
        "* Output $\\hat{y} \\in (0, 1)$ is interpreted as the probability of class 1.\n",
        "* Decision rule: $\\hat{y} \\ge 0.5 =>$ Class 1, else Class 0\n",
        "\n",
        "**Loss Function: Binary Cross-Entropy**\n",
        "\n",
        "$Loss = - \\frac{1}{n} \\Sigma[y\\log(\\hat{y}) + (1-y)\\log(1-\\hat{y})]$\n",
        "\n",
        "This penalizes wrong predictions more heavily as they get more confident and wrong."
      ],
      "metadata": {
        "id": "Z7a9D1mo6oH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "# Sample binary data\n",
        "X = np.array([[1], [2], [3], [4], [5]])\n",
        "y = np.array([0, 0, 0, 1, 1])\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict probability and class\n",
        "print(\"Probabilities:\", model.predict_proba([[3.5], [1.5]]))\n",
        "print(\"Predictions:\", model.predict([[4.5], [1.5]]))\n"
      ],
      "metadata": {
        "id": "yepLZNjV9OcS",
        "outputId": "f3cf7c7e-8606-4b31-b552-7a19ab1ac6f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilities: [[0.5208689  0.4791311 ]\n",
            " [0.89822094 0.10177906]]\n",
            "Predictions: [1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: give another example of Logistic Regression\n",
        "\n",
        "import numpy as np\n",
        "# Example 2: Predicting whether a student passes an exam based on hours studied\n",
        "\n",
        "# Sample data: Hours studied (X) and Pass (y)\n",
        "X_exam = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])\n",
        "y_exam = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1]) # 0: Fail, 1: Pass\n",
        "\n",
        "# Create and train a Logistic Regression model\n",
        "model_exam = LogisticRegression()\n",
        "model_exam.fit(X_exam, y_exam)\n",
        "\n",
        "# Predict probabilities and classes for new data (e.g., student who studied 4.5 or 7.5 hours)\n",
        "print(\"\\nExam Probabilities:\", model_exam.predict_proba([[4.5], [7.5]]))\n",
        "print(\"Exam Predictions:\", model_exam.predict([[4.5], [7.5]]))"
      ],
      "metadata": {
        "id": "xrdAB_YZ9nT5",
        "outputId": "858b6914-3aa6-4df2-f83c-f469af55e868",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exam Probabilities: [[0.49822548 0.50177452]\n",
            " [0.02784271 0.97215729]]\n",
            "Exam Predictions: [1 1]\n"
          ]
        }
      ]
    }
  ]
}